{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ§  Constrained Intelligence Constants - Interactive Tutorial\n",
    "\n",
    "Welcome to the interactive tutorial for the Constrained Intelligence Constants framework!\n",
    "\n",
    "This notebook demonstrates:\n",
    "1. Basic usage and concepts\n",
    "2. Visualization of constants\n",
    "3. Real-world applications\n",
    "4. Interactive experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the package (if needed)\n",
    "# !pip install constrained-intelligence-constants\n",
    "\n",
    "# Or use local development version\n",
    "import sys\n",
    "sys.path.insert(0, '..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from constrained_intelligence import (\n",
    "    ConstantsMeasurement,\n",
    "    OptimizationEngine,\n",
    "    BoundedSystemAnalyzer,\n",
    "    ConstantDiscovery,\n",
    "    GOLDEN_RATIO,\n",
    "    EULER_NUMBER,\n",
    "    OPTIMAL_RESOURCE_SPLIT,\n",
    ")\n",
    "\n",
    "# Plotting configuration\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. The Golden Ratio in Resource Allocation\n",
    "\n",
    "Let's visualize how the golden ratio appears in optimal resource allocation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create measurer\n",
    "measurer = ConstantsMeasurement(\n",
    "    system_type=\"resource_allocation\",\n",
    "    constraints={}\n",
    ")\n",
    "\n",
    "# Test different budget sizes\n",
    "budgets = np.linspace(100, 1000, 20)\n",
    "allocations = []\n",
    "reserves = []\n",
    "\n",
    "for budget in budgets:\n",
    "    result = measurer.measure_resource_allocation(budget)\n",
    "    allocations.append(result.empirical_evidence['optimal_allocated'])\n",
    "    reserves.append(result.empirical_evidence['reserved'])\n",
    "\n",
    "# Plot\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Plot 1: Allocation breakdown\n",
    "ax1.plot(budgets, allocations, label='Active Allocation', linewidth=2)\n",
    "ax1.plot(budgets, reserves, label='Reserve', linewidth=2)\n",
    "ax1.set_xlabel('Total Budget', fontsize=12)\n",
    "ax1.set_ylabel('Resource Units', fontsize=12)\n",
    "ax1.set_title('Resource Allocation Following Golden Ratio', fontsize=14)\n",
    "ax1.legend(fontsize=10)\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: Ratio verification\n",
    "ratios = np.array(allocations) / np.array(budgets)\n",
    "ax2.axhline(y=1/GOLDEN_RATIO, color='r', linestyle='--', label=f'Target (1/Ï† = {1/GOLDEN_RATIO:.4f})', linewidth=2)\n",
    "ax2.plot(budgets, ratios, 'o-', label='Actual Ratio', linewidth=2)\n",
    "ax2.set_xlabel('Total Budget', fontsize=12)\n",
    "ax2.set_ylabel('Allocation Ratio', fontsize=12)\n",
    "ax2.set_title('Verification: Ratio Matches 1/Ï†', fontsize=14)\n",
    "ax2.legend(fontsize=10)\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"âœ… Average ratio: {np.mean(ratios):.6f}\")\n",
    "print(f\"âœ… Target (1/Ï†): {1/GOLDEN_RATIO:.6f}\")\n",
    "print(f\"âœ… Deviation: {abs(np.mean(ratios) - 1/GOLDEN_RATIO)*100:.4f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Golden Ratio Optimization\n",
    "\n",
    "Visualize how golden section search efficiently finds the minimum of a function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define objective function\n",
    "def objective(x):\n",
    "    return (x - 7) ** 2 + 2\n",
    "\n",
    "# Optimize\n",
    "optimizer = OptimizationEngine(constraints={})\n",
    "result = optimizer.golden_ratio_optimization(\n",
    "    objective_function=objective,\n",
    "    bounds=(0, 15),\n",
    "    max_iterations=20\n",
    ")\n",
    "\n",
    "# Extract history\n",
    "history = optimizer.optimization_history\n",
    "\n",
    "# Plot\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "# Plot function\n",
    "x = np.linspace(0, 15, 300)\n",
    "y = objective(x)\n",
    "ax.plot(x, y, 'b-', linewidth=2, label='Objective Function', alpha=0.7)\n",
    "\n",
    "# Plot search points\n",
    "for i, h in enumerate(history[:10]):  # Show first 10 iterations\n",
    "    ax.plot([h['x1']], [objective(h['x1'])], 'ro', markersize=8, alpha=0.6)\n",
    "    ax.plot([h['x2']], [objective(h['x2'])], 'go', markersize=8, alpha=0.6)\n",
    "    ax.plot([h['bounds'][0], h['bounds'][1]], [objective(h['bounds'][0]), objective(h['bounds'][1])], \n",
    "            'k--', alpha=0.3, linewidth=1)\n",
    "\n",
    "# Plot optimal point\n",
    "ax.plot([result['optimal_x']], [result['optimal_value']], 'y*', \n",
    "        markersize=20, label=f\"Optimum: x={result['optimal_x']:.4f}\")\n",
    "\n",
    "ax.set_xlabel('x', fontsize=12)\n",
    "ax.set_ylabel('f(x)', fontsize=12)\n",
    "ax.set_title('Golden Ratio Search Optimization', fontsize=14)\n",
    "ax.legend(fontsize=10)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nâœ… Found optimum at x = {result['optimal_x']:.6f}\")\n",
    "print(f\"âœ… Function value: f(x) = {result['optimal_value']:.6f}\")\n",
    "print(f\"âœ… Iterations: {result['iterations']}\")\n",
    "print(f\"âœ… Converged: {result['converged']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Exponential Decay and Convergence\n",
    "\n",
    "Explore how Euler's number appears in learning convergence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create learning rate schedules\n",
    "optimizer = OptimizationEngine(constraints={})\n",
    "\n",
    "epochs = 100\n",
    "initial_lr = 1.0\n",
    "\n",
    "# Different decay constants\n",
    "decay_constants = [0.01, 0.05, 0.1, 0.2]\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Plot learning rate schedules\n",
    "for decay in decay_constants:\n",
    "    schedule = optimizer.exponential_decay_schedule(initial_lr, decay, epochs)\n",
    "    ax1.plot(schedule, label=f'Î» = {decay}', linewidth=2)\n",
    "\n",
    "ax1.axhline(y=initial_lr/EULER_NUMBER, color='r', linestyle='--', \n",
    "            label=f'1/e threshold ({initial_lr/EULER_NUMBER:.3f})', linewidth=2)\n",
    "ax1.set_xlabel('Epoch', fontsize=12)\n",
    "ax1.set_ylabel('Learning Rate', fontsize=12)\n",
    "ax1.set_title('Exponential Decay Learning Rate Schedules', fontsize=14)\n",
    "ax1.legend(fontsize=10)\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Simulate learning curves\n",
    "for decay in decay_constants:\n",
    "    # Simulate performance improvement\n",
    "    performance = [1 - np.exp(-decay * t) for t in range(epochs)]\n",
    "    ax2.plot(performance, label=f'Î» = {decay}', linewidth=2)\n",
    "\n",
    "# Mark convergence point (T/e)\n",
    "convergence_point = epochs / EULER_NUMBER\n",
    "ax2.axvline(x=convergence_point, color='r', linestyle='--', \n",
    "            label=f'Predicted convergence (T/e = {convergence_point:.1f})', linewidth=2)\n",
    "\n",
    "ax2.set_xlabel('Epoch', fontsize=12)\n",
    "ax2.set_ylabel('Performance', fontsize=12)\n",
    "ax2.set_title('Learning Convergence Curves', fontsize=14)\n",
    "ax2.legend(fontsize=10)\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nâœ… Predicted convergence at epoch: {convergence_point:.1f}\")\n",
    "print(f\"âœ… Based on factor: T/e where e = {EULER_NUMBER:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Constant Discovery\n",
    "\n",
    "Discover constants from empirical data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate synthetic data following golden ratio\n",
    "np.random.seed(42)\n",
    "true_ratio = GOLDEN_RATIO\n",
    "data_length = 15\n",
    "\n",
    "# Generate sequence with noise\n",
    "data = [100]\n",
    "for i in range(data_length - 1):\n",
    "    next_val = data[-1] / true_ratio + np.random.normal(0, 0.5)\n",
    "    data.append(next_val)\n",
    "\n",
    "# Discover constant\n",
    "discovery = ConstantDiscovery()\n",
    "result = discovery.discover_from_optimization(data, method=\"golden_ratio\")\n",
    "\n",
    "# Plot\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Plot 1: Data sequence\n",
    "ax1.plot(data, 'o-', linewidth=2, markersize=8, label='Observed Data')\n",
    "ax1.set_xlabel('Index', fontsize=12)\n",
    "ax1.set_ylabel('Value', fontsize=12)\n",
    "ax1.set_title('Optimization Trajectory', fontsize=14)\n",
    "ax1.legend(fontsize=10)\n",
    "ax1.grid(True, alpha=0.3)\n",
    "ax1.set_yscale('log')\n",
    "\n",
    "# Plot 2: Discovered ratios\n",
    "ratios = result.empirical_evidence['observed_ratios']\n",
    "ax2.hist(ratios, bins=15, alpha=0.7, edgecolor='black')\n",
    "ax2.axvline(x=GOLDEN_RATIO, color='r', linestyle='--', \n",
    "            label=f'True Golden Ratio: {GOLDEN_RATIO:.4f}', linewidth=2)\n",
    "ax2.axvline(x=result.discovered_constant, color='g', linestyle='--', \n",
    "            label=f'Discovered: {result.discovered_constant:.4f}', linewidth=2)\n",
    "ax2.set_xlabel('Ratio Value', fontsize=12)\n",
    "ax2.set_ylabel('Frequency', fontsize=12)\n",
    "ax2.set_title('Distribution of Observed Ratios', fontsize=14)\n",
    "ax2.legend(fontsize=10)\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nâœ… Discovered Constant: {result.discovered_constant:.6f}\")\n",
    "print(f\"âœ… True Golden Ratio: {GOLDEN_RATIO:.6f}\")\n",
    "print(f\"âœ… Error: {abs(result.discovered_constant - GOLDEN_RATIO):.6f}\")\n",
    "print(f\"âœ… Confidence: {result.confidence:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Interactive Experiment: Your Own Data\n",
    "\n",
    "Try discovering constants from your own data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter your own data here (or use the example)\n",
    "your_data = [100, 62, 38, 24, 15, 9, 6, 4, 2, 1]  # Example: should find Ï†\n",
    "\n",
    "# Analyze\n",
    "discovery = ConstantDiscovery()\n",
    "\n",
    "try:\n",
    "    # Try golden ratio discovery\n",
    "    result_gr = discovery.discover_from_optimization(your_data, method=\"golden_ratio\")\n",
    "    print(\"Golden Ratio Analysis:\")\n",
    "    print(f\"  Discovered: {result_gr.discovered_constant:.4f}\")\n",
    "    print(f\"  Confidence: {result_gr.confidence:.2%}\")\n",
    "    print()\n",
    "except Exception as e:\n",
    "    print(f\"Golden ratio analysis failed: {e}\\n\")\n",
    "\n",
    "try:\n",
    "    # Try exponential decay discovery\n",
    "    result_exp = discovery.discover_from_optimization(your_data, method=\"exponential_decay\")\n",
    "    print(\"Exponential Decay Analysis:\")\n",
    "    print(f\"  Time constant: {result_exp.discovered_constant:.4f}\")\n",
    "    print(f\"  Confidence: {result_exp.confidence:.2%}\")\n",
    "    print()\n",
    "except Exception as e:\n",
    "    print(f\"Exponential decay analysis failed: {e}\\n\")\n",
    "\n",
    "try:\n",
    "    # Try ratio analysis\n",
    "    result_ratio = discovery.discover_from_ratios(your_data)\n",
    "    print(\"Ratio Analysis:\")\n",
    "    print(f\"  Discovered: {result_ratio.discovered_constant:.4f}\")\n",
    "    print(f\"  Confidence: {result_ratio.confidence:.2%}\")\n",
    "except Exception as e:\n",
    "    print(f\"Ratio analysis failed: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Summary and Next Steps\n",
    "\n",
    "You've learned:\n",
    "- âœ… How the golden ratio guides resource allocation\n",
    "- âœ… How to use golden section search for optimization\n",
    "- âœ… How Euler's number appears in learning convergence\n",
    "- âœ… How to discover constants from empirical data\n",
    "\n",
    "**Next Steps:**\n",
    "1. Try the examples: `python examples/basic_usage.py`\n",
    "2. Explore advanced examples: `python examples/advanced_examples.py`\n",
    "3. Read the theory: `THEORY.md`\n",
    "4. Contribute: `CONTRIBUTING.md`\n",
    "\n",
    "**Questions?** Open an issue on GitHub!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
